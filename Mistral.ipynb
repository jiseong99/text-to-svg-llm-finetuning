{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vYkpF09LD6my"},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load #pip installations\n","\n","\n","#DOwnload and installations\n","!pip install -U bitsandbytes transformers peft accelerate trl\n","!pip install -U huggingface_hub\n","!pip install -U datasets\n","!pip install mistral-common tiktoken\n","\n","\n","#import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","#    for filename in filenames:\n","#        print(os.path.join(dirname, filename))\n"]},{"cell_type":"code","source":["#Impport statements\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging,  DataCollatorForSeq2Seq\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n","import os,torch, wandb\n","from datasets import load_dataset\n","from trl import SFTTrainer\n","from huggingface_hub import login\n","\n"],"metadata":{"id":"jI_ud26qWksO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#HUgging face login\n","login(token=\"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\", add_to_git_credential=True)\n","\n","\n","#!huggingface-cli login --token $secret_hf"],"metadata":{"id":"IgLc_AwgV3gK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#dataset loading and preprocessing.\n","dataset_name = \"starvector/text2svg-stack\"\n","#dataset = load_dataset(dataset_name, split=\"train\"[0:100])\n","dataset = load_dataset(dataset_name, split=\"train\")\n","dataset = dataset.map(lambda x: {\"Svg_length\": len(x[\"Svg\"])})\n","dataset = dataset.sort(\"Svg_length\")\n","dataset = dataset.select(range(4000))\n","#dataset[10]\n","def format_example(example):\n","    return {\n","        \"messages\": [\n","            {\"role\": \"user\", \"content\": f\"<CAPTION>\\n{example['caption_blip2']}\\n</CAPTION>\"},\n","            {\"role\": \"assistant\", \"content\": example[\"Svg\"]}\n","        ]\n","    }\n","\n","#dataset = load_dataset(\"starvector/text2svg\", split=\"train\")\n","dataset = dataset.map(format_example, remove_columns=dataset.column_names)\n","#dataset = dataset.train_test_split(test_size=250/1000)\n","print(dataset[3999])\n","\n"],"metadata":{"id":"aPYTFU1KV6Ty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit= True,\n","    bnb_4bit_quant_type= \"nf4\",\n","    bnb_4bit_compute_dtype= torch.bfloat16,\n","    bnb_4bit_use_double_quant= False,\n",")\n","\n","\n"],"metadata":{"id":"ziRQdCs8V9rY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(\n","    \"mistralai/Mistral-7B-v0.1\",\n","    quantization_config=bnb_config,\n","    torch_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","model.gradient_checkpointing_enable()\n"],"metadata":{"id":"hq8guzlwWGwi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#tokenize and start training\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", trust_remote_code=True)\n","tokenizer.padding_side = 'right'\n","tokenizer.pad_token = tokenizer.eos_token\n","#data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","#tokenizer.add_eos_token = True\n","#tokenizer.add_bos_token, tokenizer.add_eos_token\n","tokenizer.chat_template = (\n","    \"{% for message in messages %}\"\n","    \"{% if message['role'] == 'user' %}\"\n","    \"<s>[INST] {{ message['content'] }} [/INST]\"\n","    \"{% elif message['role'] == 'assistant' %}\"\n","    \"{{ message['content'] }}</s>\"\n","    \"{% endif %}\"\n","    \"{% endfor %}\"\n",")\n","\n","\n","\n","\n","\n","\n","\n","\n","model = prepare_model_for_kbit_training(model)\n","peft_config = LoraConfig(\n","    lora_alpha=32,\n","    lora_dropout=0.1,\n","    r=128,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",")\n","model = get_peft_model(model, peft_config)\n","\n"],"metadata":{"id":"UyTzFLduWTNC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#training_arguments = TrainingArguments(\n","#    output_dir=\"./results\",\n","#    num_train_epochs=4,\n","#    per_device_train_batch_size=4,\n","#    gradient_accumulation_steps=4,\n","#    optim=\"paged_adamw_32bit\",\n","#    save_steps=25,\n","#    logging_steps=25,\n","#    learning_rate=2e-4,\n","#    weight_decay=0.001,\n","#    fp16=True,\n","#    bf16=False,\n","#    max_grad_norm=0.3,\n","#    max_steps=-1,\n","#    warmup_ratio=0.03,\n","#    group_by_length=True,\n","#    lr_scheduler_type=\"constant\",\n","#    report_to=\"wandb\",\n","    #dataset_text_field=\"messages\"\n","#)\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","from trl import SFTTrainer, SFTConfig\n","\n","# Define your training configuration\n","training_config = SFTConfig(\n","    output_dir=\"./mistral-text2svg-lora\",\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    #per_device_train_batch_size=32,\n","    #gradient_accumulation_steps=32,\n","    num_train_epochs=4,\n","    learning_rate=2e-4,\n","    logging_steps=10,\n","    logging_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    fp16=True,\n","    bf16=False,\n","    logging_dir=\"./logs\",\n","    report_to=\"none\",\n","    #dataset_text_field=\"messages\",\n","    packing=False,\n","    #max_seq_length=356,\n","    #max_seq_length=580,\n","    max_seq_length=128,\n",")\n","\n","class MyTrainer(SFTTrainer):\n","    def get_train_dataloader(self):\n","        dataloader = super().get_train_dataloader()\n","        dataloader.num_workers = 2\n","        dataloader.pin_memory = True\n","        return dataloader\n","\n","\n","trainer = MyTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    args=training_config,\n","    peft_config=peft_config,\n","    processing_class=tokenizer,\n",")\n","\n","#trainer = SFTTrainer(\n","#    model=model,\n","#    train_dataset=dataset,\n","#    args=training_config,\n","#    peft_config=peft_config,\n","#    processing_class=tokenizer,\n","#)\n"],"metadata":{"id":"TDpok5ryWdGh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"J4EORfwQWesc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#device = model.device\n","\n","#inputs = {k: v.to(device) for k, v in inputs.items()}  # during forward pass"],"metadata":{"id":"tS-fer1PXAyu"},"execution_count":null,"outputs":[]}]}